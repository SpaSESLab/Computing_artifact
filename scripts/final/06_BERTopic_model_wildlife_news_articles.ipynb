{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#1introduction\n",
    "#importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import spacy\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf  # if you are using tensorflow\n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#spacy\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#vis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from bertopic import BERTopic\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the Documentt Term Matrix-DTM (collection of documents where each row corresponds to a document and each column represents a unique term (word))\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "readRDS = robjects.r['readRDS']\n",
    "dtm_r = readRDS(\"clean_dtm.rds\")\n",
    "#print(dtm_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame frpm DTM\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Data extraction\n",
    "rows = [x - 1 for x in list(dtm_r.rx2('i'))]\n",
    "cols = [x - 1 for x in list(dtm_r.rx2('j'))]\n",
    "data = list(dtm_r.rx2('v'))\n",
    "nrow = int(dtm_r.rx2('nrow')[0])\n",
    "ncol = int(dtm_r.rx2('ncol')[0])\n",
    "terms = list(dtm_r.rx2('dimnames')[1])\n",
    "docs = list(dtm_r.rx2('dimnames')[0])\n",
    "\n",
    "# Creating sparse matrix and convert to dense array\n",
    "mtx = coo_matrix((data, (rows, cols)), shape=(nrow, ncol)).toarray()\n",
    "\n",
    "df = pd.DataFrame(mtx, columns=terms, index=docs)\n",
    "#df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating text string to use for the Bertopic model\n",
    "def row_to_text(row):\n",
    "    words = []\n",
    "    for col, count in row.items():\n",
    "        try:\n",
    "            repetitions = int(count)\n",
    "        except (ValueError, TypeError):\n",
    "            repetitions = 0\n",
    "        if repetitions > 0:\n",
    "            words.extend([col]*repetitions)\n",
    "    return ' '.join(words)\n",
    "\n",
    "texts = df.apply(row_to_text, axis=1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b45f2bf4ef499b8887096300eeeed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 13:44:02,784 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-11-13 13:44:09,729 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-11-13 13:44:09,731 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-11-13 13:44:09,814 - BERTopic - Cluster - Completed ✓\n",
      "2025-11-13 13:44:09,822 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-11-13 13:44:10,548 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Topic  Count                                         Name  \\\n",
      "0      -1      5                     -1_dam_tower_fire_forest   \n",
      "1       0    840                  0_animal_wolf_wildlife_year   \n",
      "2       1    724              1_wildlife_fish_federal_service   \n",
      "3       2    648                2_federal_wildlife_us_service   \n",
      "4       3    621                 3_water_fish_california_year   \n",
      "5       4    593  4_environmental_federal_administration_year   \n",
      "6       5    526              5_california_fish_water_federal   \n",
      "7       6    434                      6_court_state_case_vote   \n",
      "8       7    377                      7_bear_alaska_wolf_year   \n",
      "9       8    258           8_environmental_year_activist_land   \n",
      "10      9     28                            9_am_subc_rhob_pm   \n",
      "\n",
      "                                       Representation  \\\n",
      "0   [dam, tower, fire, forest, burn, klamath, remo...   \n",
      "1   [animal, wolf, wildlife, year, state, populati...   \n",
      "2   [wildlife, fish, federal, service, agency, hab...   \n",
      "3   [federal, wildlife, us, service, fish, protect...   \n",
      "4   [water, fish, california, year, river, state, ...   \n",
      "5   [environmental, federal, administration, year,...   \n",
      "6   [california, fish, water, federal, state, wild...   \n",
      "7   [court, state, case, vote, justice, republican...   \n",
      "8   [bear, alaska, wolf, year, polar, state, fish,...   \n",
      "9   [environmental, year, activist, land, state, g...   \n",
      "10  [am, subc, rhob, pm, dob, approps, office, app...   \n",
      "\n",
      "                                  Representative_Docs  \n",
      "0   [activity age agency agency ago ago ago allow ...  \n",
      "1   [ability ability ability agency ago ago ago an...  \n",
      "2   [activity agency agency agency allow allow ani...  \n",
      "3   [agency animal call court environmental execut...  \n",
      "4   [adopt adopt agency agency answer area area ar...  \n",
      "5   [ability ability ability account address agenc...  \n",
      "6   [address agency agency animal approve area are...  \n",
      "7   [ability activity adopt adopt adopt appeal app...  \n",
      "8   [activity adopt alaska animal animal animal an...  \n",
      "9   [activist activist activist activist activist ...  \n",
      "10  [activity age agency agency agency area bureau...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from bertopic import BERTopic\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import umap\n",
    "\n",
    "# Set seeds for python and numpy for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Configure UMAP with fixed random state and desired params\n",
    "umap_model = umap.UMAP(random_state=42, n_neighbors=15, min_dist=0.1, metric='cosine')\n",
    "\n",
    "# Encoding documents\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "# KMeans clustering with fixed random state\n",
    "kmeans_model = KMeans(n_clusters=9, random_state=42)\n",
    "predicted_topics = kmeans_model.fit_predict(embeddings)\n",
    "\n",
    "# Instantiating BERTopic with fixed UMAP model for full reproducibility\n",
    "topic_model = BERTopic(\n",
    "    language=\"english\",\n",
    "    nr_topics=None,\n",
    "    umap_model=umap_model,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Fitting the model\n",
    "topics, probs = topic_model.fit_transform(texts, embeddings=embeddings, y=predicted_topics)\n",
    "\n",
    "\n",
    "print(topic_model.get_topic_info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a DataFrame of the topic info (includes keywords as a string)\n",
    "topic_info = topic_model.get_topic_info()\n",
    "\n",
    "topic_keywords = []\n",
    "for topic_num in topic_info['Topic']:\n",
    "    if topic_num == -1:  # getting rid of the outlier topic\n",
    "        continue\n",
    "    keywords = topic_model.get_topic(topic_num)\n",
    "    # Getting the word list\n",
    "    word_list = [kw[0] for kw in keywords]\n",
    "    # Save topic number, full keyword string, and/or list\n",
    "    topic_keywords.append({'Topic': topic_num, 'keywords': ', '.join(word_list)})\n",
    "\n",
    "# Making a DataFrame and save to CSV\n",
    "keywords_df = pd.DataFrame(topic_keywords)\n",
    "keywords_df.to_csv(\"wildlife_bertopic_keywords.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic                                           keywords\n",
      "0      0  animal, wolf, wildlife, year, state, populatio...\n",
      "1      1  wildlife, fish, federal, service, agency, habi...\n",
      "2      2  federal, wildlife, us, service, fish, protect,...\n",
      "3      3  water, fish, california, year, river, state, s...\n",
      "4      4  environmental, federal, administration, year, ...\n",
      "5      5  california, fish, water, federal, state, wildl...\n",
      "6      6  court, state, case, vote, justice, republican,...\n",
      "7      7  bear, alaska, wolf, year, polar, state, fish, ...\n",
      "8      8  environmental, year, activist, land, state, gr...\n",
      "9      9  am, subc, rhob, pm, dob, approps, office, appr...\n"
     ]
    }
   ],
   "source": [
    "print(keywords_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df.to_csv(\"wildlife_bertopic_keywords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a datframe with topic number, single keyword, and its weight\n",
    "records = []\n",
    "for topic_num in topic_model.get_topic_info()['Topic']:\n",
    "    if topic_num == -1:\n",
    "        continue  # Skip outlier topic\n",
    "    for kw, wt in topic_model.get_topic(topic_num):\n",
    "        records.append({\n",
    "            \"topic\": topic_num,\n",
    "            \"keyword\": kw,\n",
    "            \"weight\": wt\n",
    "        })\n",
    "\n",
    "bertopic_keywords_df = pd.DataFrame(records)\n",
    "bertopic_keywords_df.to_csv(\"wildlife_bertopic_keywords_with_weights_01.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    topic        keyword    weight\n",
      "0       0         animal  0.029065\n",
      "1       0           wolf  0.026146\n",
      "2       0       wildlife  0.021663\n",
      "3       0           year  0.019931\n",
      "4       0          state  0.016962\n",
      "..    ...            ...       ...\n",
      "95      9        approps  0.062123\n",
      "96      9         office  0.060734\n",
      "97      9  appropriation  0.058197\n",
      "98      9           bldg  0.053067\n",
      "99      9         affair  0.045656\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(bertopic_keywords_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        GOID  Topic\n",
      "0  423968056      6\n",
      "1  423987935      6\n",
      "2  423991776      3\n",
      "3  424019341      2\n",
      "4  424018521      0\n"
     ]
    }
   ],
   "source": [
    "doc_topic_df = pd.DataFrame({'GOID': docs, 'Topic': topics})\n",
    "print(doc_topic_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_df.to_csv('document_topic_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want a count of keywords for the wordcloud\n",
    "\n",
    "keyword_counts = bertopic_keywords_df.groupby('keyword').size().reset_index(name='count')\n",
    "\n",
    "#print(keyword_counts.sort_values(by='count', ascending=False))\n",
    "\n",
    "keyword_counts.to_csv('Bertopic_keyword_counts_for_news.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    topic    keyword    weight\n",
      "0       1      water  0.041614\n",
      "1       1      river  0.022201\n",
      "2       1       fish  0.021578\n",
      "3       1     salmon  0.019609\n",
      "4       1       year  0.012008\n",
      "..    ...        ...       ...\n",
      "95      9   industry  0.007591\n",
      "96      9    federal  0.007367\n",
      "97      9        log  0.007273\n",
      "98      9        oil  0.007220\n",
      "99      9  president  0.006944\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "stm_words = pd.read_csv(\"news_stm_topic_keywords_with_weights.csv\")\n",
    "print(stm_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting keywords in stm\n",
    "\n",
    "keyword_counts_stm = stm_words.groupby('keyword').size().reset_index(name='count')\n",
    "\n",
    "#print(keyword_counts_stm)\n",
    "\n",
    "keyword_counts_stm.to_csv('STM_keyword_counts_for_news.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   topic     keyword    weight\n",
      "0      1       water  0.041614\n",
      "1      1       river  0.022201\n",
      "2      1        fish  0.021578\n",
      "3      1      salmon  0.019609\n",
      "4      1        year  0.012008\n",
      "5      1         dam  0.011465\n",
      "6      1  california  0.010442\n",
      "7      1       state  0.010006\n",
      "8      1     federal  0.009816\n",
      "9      1      farmer  0.008259\n"
     ]
    }
   ],
   "source": [
    "#To check the topic and see the weights of the keywords\n",
    "filtered_topic = stm_words[stm_words['topic'] == 1]\n",
    "print(filtered_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'topic': 1, 'keywords': {'year', 'dam', 'river', 'federal', 'water', 'california', 'state', 'farmer', 'fish', 'salmon'}}, {'topic': 2, 'keywords': {'time', 'sea', 'year', 'otter', 'turtle', 'water', 'butterfly', 'fish', 'whale', 'marine'}}, {'topic': 3, 'keywords': {'year', 'congress', 'house', 'bill', 'vote', 'republican', 'environmental', 'clinton', 'senate', 'state'}}, {'topic': 4, 'keywords': {'wolf', 'year', 'grizzly', 'kill', 'wildlife', 'state', 'bear', 'park', 'hunt', 'animal'}}, {'topic': 5, 'keywords': {'service', 'list', 'federal', 'wildlife', 'protect', 'threaten', 'protection', 'agency', 'fish', 'habitat'}}]\n"
     ]
    }
   ],
   "source": [
    "#did this so that i can use it for the cosine similarity\n",
    "# Group keywords by topic, using set for easy overlap checking\n",
    "stm_topics = []\n",
    "for topic, group in stm_words.groupby('topic'):\n",
    "    keywords = set(group['keyword'])\n",
    "    stm_topics.append({'topic': topic, 'keywords': keywords})\n",
    "\n",
    "print(stm_topics[:5])  # Shows the first 5 topics in your desired format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source Type</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication ID</th>\n",
       "      <th>Publication Title</th>\n",
       "      <th>Publisher City</th>\n",
       "      <th>Publisher Province</th>\n",
       "      <th>Publisher Name</th>\n",
       "      <th>Publisher ZipCode</th>\n",
       "      <th>Object Type</th>\n",
       "      <th>Language</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Start Page</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company NAIC</th>\n",
       "      <th>Class Terms</th>\n",
       "      <th>Subject Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>433375738</td>\n",
       "      <td>Park Service To Emphasize Conservation In New ...</td>\n",
       "      <td>2006-08-31</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>['Barringer, Felicity']</td>\n",
       "      <td>11561</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York Times Company</td>\n",
       "      <td>10018.0</td>\n",
       "      <td>Articles - All Types</td>\n",
       "      <td>English</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A.16</td>\n",
       "      <td>['National Park Service-US']</td>\n",
       "      <td>['924120']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Conservation', 'Recreation industry', 'Envir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GOID                                              Title        Date  \\\n",
       "0  433375738  Park Service To Emphasize Conservation In New ...  2006-08-31   \n",
       "\n",
       "  Source Type                  Authors  Publication ID Publication Title  \\\n",
       "0  Newspapers  ['Barringer, Felicity']           11561    New York Times   \n",
       "\n",
       "  Publisher City Publisher Province          Publisher Name  \\\n",
       "0       NEW YORK                 NY  New York Times Company   \n",
       "\n",
       "   Publisher ZipCode           Object Type Language  Pages Start Page  \\\n",
       "0            10018.0  Articles - All Types  English    0.0       A.16   \n",
       "\n",
       "                   Company Name Company NAIC Class Terms  \\\n",
       "0  ['National Park Service-US']   ['924120']         NaN   \n",
       "\n",
       "                                       Subject Terms  \n",
       "0  ['Conservation', 'Recreation industry', 'Envir...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"meta.csv\")\n",
    "metadata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5241, 19)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        GOID        Date\n",
      "0  433375738  2006-08-31\n",
      "1  433422646  2006-10-31\n",
      "2  433462991  2006-12-28\n",
      "3  433470077  2006-12-11\n",
      "4  433481259  2007-01-30\n"
     ]
    }
   ],
   "source": [
    "#getting only GOID and Date from metadata\n",
    "columns_to_keep = ['GOID', 'Date']\n",
    "\n",
    "# Create a new DataFrame with only these columns\n",
    "new_df = metadata[columns_to_keep]\n",
    "\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>GOID</th>\n",
       "      <th>topic</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>423968056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>423987935</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       GOID  topic     gamma\n",
       "0           1  423968056      1  0.002298\n",
       "1           2  423987935      1  0.001456"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stm_gamma = pd.read_csv(\"stm_gamma.csv\")\n",
    "stm_gamma.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50540, 4)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stm_gamma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0       GOID  topic     gamma\n",
      "0               1  423968056      1  0.002298\n",
      "5054         5055  423968056      2  0.168195\n",
      "10108       10109  423968056      3  0.071988\n",
      "15162       15163  423968056      4  0.078102\n",
      "20216       20217  423968056      5  0.075703\n",
      "25270       25271  423968056      6  0.355744\n",
      "30324       30325  423968056      7  0.048214\n",
      "35378       35379  423968056      8  0.003927\n",
      "40432       40433  423968056      9  0.188588\n",
      "45486       45487  423968056     10  0.007241\n"
     ]
    }
   ],
   "source": [
    "#i wanted to filter and check how many topics each GOID has\n",
    "filtered_row = stm_gamma[stm_gamma['GOID'] == 423968056]\n",
    "print(filtered_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       GOID  topic     gamma\n",
      "0       47716  109846173     10  0.378097\n",
      "1       44429  276285002      9  0.604291\n",
      "2       44430  276531081      9  0.702650\n",
      "3         265  280504819      1  0.532866\n",
      "4       15434  280508448      4  0.461570\n"
     ]
    }
   ],
   "source": [
    "# Keep only the row with the highest gamma per GOID..after realising that each document will have 10 topics\n",
    "best_topic_per_goid = stm_gamma.loc[stm_gamma.groupby('GOID')['gamma'].idxmax()].reset_index(drop=True)\n",
    "print(best_topic_per_goid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "GOID            int64\n",
       "topic           int64\n",
       "gamma         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_topic_per_goid.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOID</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>433375738</td>\n",
       "      <td>2006-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433422646</td>\n",
       "      <td>2006-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>433462991</td>\n",
       "      <td>2006-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>433470077</td>\n",
       "      <td>2006-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433481259</td>\n",
       "      <td>2007-01-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GOID        Date\n",
       "0  433375738  2006-08-31\n",
       "1  433422646  2006-10-31\n",
       "2  433462991  2006-12-28\n",
       "3  433470077  2006-12-11\n",
       "4  433481259  2007-01-30"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GOID     int64\n",
       "Date    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       GOID  topic     gamma        Date\n",
      "0       47716  109846173     10  0.378097  1998-08-02\n",
      "1       44429  276285002      9  0.604291  2010-05-14\n",
      "2       44430  276531081      9  0.702650  2010-05-15\n",
      "3         265  280504819      1  0.532866  1988-08-31\n",
      "4       15434  280508448      4  0.461570  1988-09-22\n"
     ]
    }
   ],
   "source": [
    "# Merge best_topic_per_goid with new_df on 'GOID'\n",
    "best_topic_per_goid_merged = best_topic_per_goid.merge(new_df, on='GOID', how='left')\n",
    "print(best_topic_per_goid_merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GOID    object\n",
       "Date    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['GOID'] = new_df['GOID'].astype(str)\n",
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GOID     object\n",
       "Topic     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting both the GOID and Topic to string(object) datatype\n",
    "doc_topic_df['GOID'] = doc_topic_df['GOID'].astype(str)\n",
    "doc_topic_df['Topic'] = doc_topic_df['Topic'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge DataFrames on 'GOID'\n",
    "merged_df_bertopic = pd.merge(new_df, doc_topic_df[['GOID', 'Topic']], on='GOID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>433375738</td>\n",
       "      <td>2006-08-31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433422646</td>\n",
       "      <td>2006-10-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>433462991</td>\n",
       "      <td>2006-12-28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>433470077</td>\n",
       "      <td>2006-12-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433481259</td>\n",
       "      <td>2007-01-30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GOID        Date Topic\n",
       "0  433375738  2006-08-31     4\n",
       "1  433422646  2006-10-31     0\n",
       "2  433462991  2006-12-28     7\n",
       "3  433470077  2006-12-11     0\n",
       "4  433481259  2007-01-30     7"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_bertopic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       GOID  topic     gamma        Date\n",
      "0       47716  109846173     10  0.378097  1998-08-02\n",
      "1       44429  276285002      9  0.604291  2010-05-14\n",
      "2       44430  276531081      9  0.702650  2010-05-15\n",
      "3         265  280504819      1  0.532866  1988-08-31\n",
      "4       15434  280508448      4  0.461570  1988-09-22\n"
     ]
    }
   ],
   "source": [
    "print(best_topic_per_goid_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure 'topic' is integer with no decimals\n",
    "merged_df_bertopic['Topic'] = merged_df_bertopic['Topic'].astype('Int64') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>433375738</td>\n",
       "      <td>2006-08-31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433422646</td>\n",
       "      <td>2006-10-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>433462991</td>\n",
       "      <td>2006-12-28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>433470077</td>\n",
       "      <td>2006-12-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433481259</td>\n",
       "      <td>2007-01-30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GOID        Date  Topic\n",
       "0  433375738  2006-08-31      4\n",
       "1  433422646  2006-10-31      0\n",
       "2  433462991  2006-12-28      7\n",
       "3  433470077  2006-12-11      0\n",
       "4  433481259  2007-01-30      7"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_bertopic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_bertopic.to_csv(\"Wildlife_news_articles_BERTopic_topics.csv\", index=False)\n",
    "\n",
    "best_topic_per_goid_merged.to_csv(\"Wildlife_news_articles_STM_topics.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
